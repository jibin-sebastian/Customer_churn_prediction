algorithms:
  # logistic_classifier:
  #   model: "LogisticRegression"
  #   param_grid:
  #     - penalty: [l1]
  #       C: [0.001, 0.01, 0.1, 1, 10, 100]
  #       solver: [liblinear, saga]
  #     - penalty: [l2]
  #       C: [0.001, 0.01, 0.1, 1, 10, 100]
  #       solver: [newton-cg, lbfgs, sag, saga, liblinear]
  # DecisionTreeClassifier:
  #   model: "DecisionTreeClassifier"
  #   param_grid:
  #     criterion: [gini, entropy]
  #     max_depth: [1, 10, 20, 30, 40, 50]
  #     min_samples_split: [2, 5, 10]
  #     min_samples_leaf: [1, 2, 4]
  #     max_features: [1, 2, 3, 4, 5, 6]
  KNeighborsClassifier:
    model: "KNeighborsClassifier"
    param_grid:
      n_neighbors: [3,5,7,9,11,13,15,20,25]
      weights: ['uniform', 'distance']
      metric: ['euclidean', 'manhattan', 'minkowski']
  # SVC:
  #   model: "SVC"
  #   param_grid:
  #     C: [0.1, 1, 10, 50, 100, 500, 1000]
  #     kernel: ['linear', 'poly', 'rbf', 'sigmoid']
  #     degree: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
  #     gamma: ['scale', 'auto']
  # RandomForestClassifier:
  #   model: "RandomForestClassifier"
  #   param_grid:
  #     n_estimators: [10, 50, 100, 500]
  #     criterion: ['gini', 'entropy']
  #     max_depth: [10, 20, 50]
  #     min_samples_split: [2, 5, 10]
  #     min_samples_leaf: [1, 2, 4]
  #     max_features: ['sqrt', 'log2']
